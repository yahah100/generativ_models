{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYmjXBrTQPMz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot  as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhhQESV2jqTf"
   },
   "source": [
    "## Aufgabe 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XO2VwLusQpWJ"
   },
   "outputs": [],
   "source": [
    "def sample_data():\n",
    "  count = 10000\n",
    "  rand = np.random.RandomState(0)\n",
    "  a = 0.3 + 0.1 * rand.randn(count)\n",
    "  b = 0.8 + 0.05 * rand.randn(count)\n",
    "  mask = rand.rand(count) < 0.5\n",
    "  samples = np.clip(a * mask + b * (1 - mask), 0.0, 1.0)\n",
    "  return np.digitize(samples, np.linspace(0.0, 1.0, 100))\n",
    "\n",
    "sample_data = sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPlgam5w-0xy"
   },
   "outputs": [],
   "source": [
    "BATCHSIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SP2nPWY4TChf"
   },
   "outputs": [],
   "source": [
    "def create_batch(x): \n",
    "  unique, counts = np.unique(x, return_counts=True)\n",
    "  dict_counts = dict(zip(unique, counts))\n",
    "  label = []\n",
    "  for i in range(BATCHSIZE):\n",
    "    label.append(dict_counts[x[i]]/BATCHSIZE)  \n",
    "  label = np.array(label)\n",
    "  return x, label\n",
    "\n",
    "dataset = []\n",
    "for data in range(0, int(10000/BATCHSIZE)):\n",
    "  x,y = create_batch(sample_data[data:(data+BATCHSIZE)])\n",
    "\n",
    "  x = torch.from_numpy(x)\n",
    "  y = torch.from_numpy(y).float()\n",
    "  dataset.append((x,y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "mCkG_MCl62w2",
    "outputId": "1261b2fc-f1f9-4a15-b80e-9f8ff9bd23b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl an Batches Insgesamt:  100\n",
      "train batches: 80\n",
      "test batches: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Anzahl an Batches Insgesamt: \", len(dataset))\n",
    "train_ds = dataset[:80]\n",
    "test_ds = dataset[80:]\n",
    "\n",
    "print(\"train batches:\", len(train_ds))\n",
    "print(\"test batches:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "NKXiH7AcZVd0",
    "outputId": "411f13cb-34b1-4bb2-d54c-e5783b6af199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \t torch.Size([100]) torch.int64\n",
      "label: \t torch.Size([100]) torch.float32\n",
      "Example:\n",
      "tensor([48, 76, 88, 81, 79]) tensor([0.0100, 0.0300, 0.0100, 0.0600, 0.0300])\n"
     ]
    }
   ],
   "source": [
    "print(\"x: \\t\", train_ds[0][0].shape, train_ds[0][0].dtype)\n",
    "print(\"label: \\t\", train_ds[0][1].shape, train_ds[0][1].dtype)\n",
    "print(\"Example:\")\n",
    "print(train_ds[0][0][:5], train_ds[0][1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blvymBm6uTrX"
   },
   "outputs": [],
   "source": [
    "theta = torch.zeros(100, requires_grad=True)\n",
    "\n",
    "def my_model(x):\n",
    "  # (N) to (N,C)\n",
    "  x = torch.nn.functional.one_hot(x, 100)\n",
    "  x_1 = torch.exp(x * theta)\n",
    "  # print(\"x_1: \", x_1.shape)\n",
    "\n",
    "  sum_x = torch.zeros(100, 100)\n",
    "\n",
    "  for x_2 in torch.arange(100):\n",
    "     x_2 = torch.nn.functional.one_hot(x_2, 100)\n",
    "     sum_x += torch.exp(x_2 * theta)\n",
    "  res = x_1 / sum_x\n",
    "  # print(\"res: \", res.shape)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7YCpY8QwrId"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([theta], lr=0.001, momentum=0.9)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIeqrvxgkdA5"
   },
   "source": [
    "I don't get how to process the data. The NLLL needs indices(long) as input and I have floats.\n",
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y-hWkOAVBWZG"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "VLZ-BJaxnRgs",
    "outputId": "036429d8-26ef-4bf1-c827-73f255439d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([100, 100])\n",
      "Output: torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d9c00fe77d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print(\"Output:\", outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'target' in call to _thnn_nll_loss_forward"
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "loss_list = []\n",
    "for epoch in range(EPOCH):\n",
    "  for i, data in enumerate(train_ds, 0):\n",
    "\n",
    "    inputs, labels = data\n",
    "    # labels = torch.nn.functional.one_hot(labels, 100)\n",
    "    # print(\"Labels:\", labels.shape)\n",
    "    # print(\"Input:\", inputs.shape)\n",
    "\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = my_model(inputs)\n",
    "    print(\"Output:\", outputs.shape)\n",
    "    print(\"Output:\", outputs.dtype)\n",
    "    # print(\"Output:\", outputs)\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    print(\"epoch: \", epoch, \"i:\" , i, \"loss: \", loss.item())\n",
    "    loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rjLjYrFTddx"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNpyvyRnBZpL"
   },
   "source": [
    "## Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3rZB1XVTdjd"
   },
   "outputs": [],
   "source": [
    " test_loss = []\n",
    " for i, data in enumerate(test_ds, 0):\n",
    "\n",
    "    inputs, labels = data\n",
    "\n",
    "    outputs = my_model(inputs)\n",
    "    # print(\"Output:\", outputs.shape)\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # print statistics\n",
    "    print(i, \": loss \", loss.item())\n",
    "    test_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unSC4DQkBhdQ"
   },
   "outputs": [],
   "source": [
    "plt.plot(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bm5bYqazG4Rv"
   },
   "source": [
    "## Aufgabe 1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "OUfOOl6EBhjm",
    "outputId": "d03cfc78-1897-4994-cd56-16420f96e176"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_plot = sample_data[0:1000]\n",
    "plt.hist(model_plot, bins=100)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "6KaCXFoLBhm_",
    "outputId": "dc947f82-b951-4f80-a314-7be5bdf448f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model_ouput = []\n",
    "for i in range(10):\n",
    "  random_sample = np.random.choice(100, 100)\n",
    "  result = my_model(torch.from_numpy(random_sample)).detach().numpy()\n",
    "  argmax = np.argmax(result, axis=0)\n",
    "  for i in argmax:\n",
    "    my_model_ouput.append(i)\n",
    "plt.hist(my_model_ouput, bins=100)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_-lGETBTdbo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IorUZyAdONki"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "exercise01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
