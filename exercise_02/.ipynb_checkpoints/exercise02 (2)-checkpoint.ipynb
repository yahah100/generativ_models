{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7f2UGEYiWjH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import pickle\n",
    "\n",
    "\n",
    "import matplotlib.pyplot  as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yNQLvG7YihTk",
    "outputId": "e7a3970b-db31-46fc-b737-4d39c09f86ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVc-FD4wiiPm"
   },
   "outputs": [],
   "source": [
    "with open('colored-mnist.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbpAsNW0iiS0"
   },
   "outputs": [],
   "source": [
    "train = data['train']\n",
    "test = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "7yACKEVPiiWU",
    "outputId": "96d4f01c-65e6-4270-830b-5e576990ab1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count train samples:  60000\n",
      "Count test samples:  10000\n",
      "Shape of image (H, W, C):  (28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Count train samples: \", train.shape[0])\n",
    "print(\"Count test samples: \", test.shape[0])\n",
    "print(\"Shape of image (H, W, C): \", train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "mkIyxgunAOkw",
    "outputId": "d6cd818e-1794-40ac-f956-9731fae1843f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "def show_image(i, image): \n",
    "  print_image =  image * (256 / 3)\n",
    "  fig.add_subplot(1, 4, i+1)\n",
    "  plt.imshow(print_image.astype(int))\n",
    "  \n",
    "\n",
    "for i in range(0, 4):\n",
    "  show_image(i, train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZblPjcNe-9iI"
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, target, transform=None):\n",
    "      self.target = torch.from_numpy(target).view(-1, 3, 28, 28)\n",
    "      self.transform = transform\n",
    "      \n",
    "  def __getitem__(self, index):\n",
    "      y = self.target[index]\n",
    "      \n",
    "      if self.transform:\n",
    "          y = self.transform(y)\n",
    "          \n",
    "      return y\n",
    "  \n",
    "  def __len__(self):\n",
    "      return len(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udbU4oDE_DxO"
   },
   "outputs": [],
   "source": [
    "BATCHSIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_x1ZITM_CN8"
   },
   "outputs": [],
   "source": [
    "train_ds = MyDataset(train)\n",
    "test_ds = MyDataset(test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=BATCHSIZE)\n",
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kKwBHSvWTgTJ",
    "outputId": "7a9b8777-6eea-4692-a54f-a700f2fe5af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape:  torch.Size([100, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "labels = dataiter.next()\n",
    "print(\"Tensor shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qr3-rgT0Tgv4"
   },
   "source": [
    "## Masking\n",
    "\n",
    "- ConvLayer 7x7 needs Mask A\n",
    "\n",
    "- The Convlayers in the residual Blocks need the Mask B \n",
    "\n",
    "\n",
    "### Example for 3x3 Filter\n",
    "- Mask A:\n",
    "$\\left( \\begin{array}{rrr}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{array}\\right) $\n",
    "\n",
    "- Mask B:\n",
    "$\\left( \\begin{array}{rrr}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{array}\\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULnS0vdKlLSl"
   },
   "outputs": [],
   "source": [
    "# Quelle: https://www.codeproject.com/Articles/5061271/PixelCNN-in-Autoregressive-Models\n",
    "class MaskedConv2d(torch.nn.Conv2d):\n",
    "  def __init__(self, mask_type, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    assert mask_type in ('A', 'B')\n",
    "    self.register_buffer('mask', self.weight.data.clone())\n",
    "    _, _, fH, fW = self.weight.size()\n",
    "    \n",
    "    self.mask.fill_(1)\n",
    "    if (mask_type == 'B'): \n",
    "      self.mask[:, :, fH // 2, fW // 2 + 1:] = 0\n",
    "    else:\n",
    "      self.mask[:, :, fH // 2, fW // 2:] = 0\n",
    "    \n",
    "    self.mask[:, :, fH // 2 + 1:] = 0\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.weight.data *= self.mask\n",
    "    return super(MaskedConv2d, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPLZeWQblLV8"
   },
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, channels=128):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.channels=channels\n",
    "\n",
    "    self.network = torch.nn.Sequential(\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(self.channels*2,self.channels, 1, stride=1, padding=0), \n",
    "        torch.nn.BatchNorm2d(self.channels), \n",
    "        torch.nn.ReLU(),\n",
    "        MaskedConv2d('B',self.channels, self.channels, 3, stride=1, padding=1),\n",
    "        torch.nn.BatchNorm2d(self.channels), \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(self.channels,self.channels*2, 1, stride=1, padding=0),\n",
    "        torch.nn.BatchNorm2d(2*self.channels)\n",
    "      )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out= self.network(x)\n",
    "    return x + out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWSPjoPklLY6"
   },
   "outputs": [],
   "source": [
    "class PixelCNN(torch.nn.Module):\n",
    "    \n",
    "  def __init__(self, channels=128, res_blocks=12): \n",
    "    super(PixelCNN,self).__init__()\n",
    "    layers = []\n",
    "    layers.append(MaskedConv2d(\"A\", 3, channels*2, 7, padding=3))\n",
    "\n",
    "    for i in range(res_blocks):\n",
    "      layers.append(ResBlock(channels))\n",
    "\n",
    "    # layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Conv2d(channels*2, 1024, 1, 1, 0))\n",
    "    layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Conv2d(1024, 3*4, 1, 1, 0))\n",
    "    layers.append(torch.nn.Softmax())\n",
    "\n",
    "    self.network = torch.nn.Sequential(*layers)\n",
    "   \n",
    "  def forward(self, x):\n",
    "    out = self.network(x)\n",
    "    return out.view(-1,4,3,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okFtCy5GlLbq"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PixelCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e0c1b65520e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpixelCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPixelCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PixelCNN' is not defined"
     ]
    }
   ],
   "source": [
    "pixelCNN = PixelCNN(128).to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  pixelCNN = torch.nn.DataParallel(pixelCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "my1aMqqcQ1XX",
    "outputId": "0564445c-2a62-4431-a7fb-6d69a41b5f54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zCd10d9owmqR",
    "outputId": "9cd368fd-9ad6-4e94-b83f-9f441a2ed978"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_F2HkkAiiZ6"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pixelCNN.parameters(),lr=3e-4, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UoREGLUX2YtC",
    "outputId": "a5c688d4-9b9c-43b7-fa9f-86243cd2f9d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 i: 9 loss: 1.2036070823669434 val loss: 1.202981948852539\n",
      "epoch: 0 i: 19 loss: 1.1893919706344604 val loss: 1.1918643712997437\n",
      "epoch: 0 i: 29 loss: 1.180776834487915 val loss: 1.185837984085083\n",
      "epoch: 0 i: 39 loss: 1.178886890411377 val loss: 1.181936264038086\n",
      "epoch: 0 i: 49 loss: 1.1766414642333984 val loss: 1.1791659593582153\n",
      "epoch: 0 i: 59 loss: 1.1762617826461792 val loss: 1.1770440340042114\n",
      "epoch: 0 i: 69 loss: 1.1733132600784302 val loss: 1.175486445426941\n",
      "epoch: 0 i: 79 loss: 1.1751742362976074 val loss: 1.1745244264602661\n",
      "epoch: 0 i: 89 loss: 1.170861005783081 val loss: 1.173814058303833\n",
      "epoch: 0 i: 99 loss: 1.172199010848999 val loss: 1.172569990158081\n",
      "epoch: 0 i: 109 loss: 1.1705189943313599 val loss: 1.1721450090408325\n",
      "epoch: 0 i: 119 loss: 1.1704310178756714 val loss: 1.1710906028747559\n",
      "epoch: 0 i: 129 loss: 1.1706583499908447 val loss: 1.1708914041519165\n",
      "epoch: 0 i: 139 loss: 1.1708133220672607 val loss: 1.1701840162277222\n",
      "epoch: 0 i: 149 loss: 1.165945053100586 val loss: 1.1688858270645142\n",
      "epoch: 0 i: 159 loss: 1.1685545444488525 val loss: 1.1682826280593872\n",
      "epoch: 0 i: 169 loss: 1.1659224033355713 val loss: 1.1678225994110107\n",
      "epoch: 0 i: 179 loss: 1.1665911674499512 val loss: 1.1672914028167725\n",
      "epoch: 0 i: 189 loss: 1.1652326583862305 val loss: 1.1666721105575562\n",
      "epoch: 0 i: 199 loss: 1.1677190065383911 val loss: 1.1660650968551636\n",
      "epoch: 0 i: 209 loss: 1.165308952331543 val loss: 1.1656938791275024\n",
      "epoch: 0 i: 219 loss: 1.1656521558761597 val loss: 1.1653653383255005\n",
      "epoch: 0 i: 229 loss: 1.1643036603927612 val loss: 1.1649447679519653\n",
      "epoch: 0 i: 239 loss: 1.163840651512146 val loss: 1.1644668579101562\n",
      "epoch: 0 i: 249 loss: 1.1624948978424072 val loss: 1.164294719696045\n",
      "epoch: 0 i: 259 loss: 1.1639221906661987 val loss: 1.1640119552612305\n",
      "epoch: 0 i: 269 loss: 1.162755012512207 val loss: 1.1634491682052612\n",
      "epoch: 0 i: 279 loss: 1.1625481843948364 val loss: 1.1634021997451782\n",
      "epoch: 0 i: 289 loss: 1.1644542217254639 val loss: 1.163432240486145\n",
      "epoch: 0 i: 299 loss: 1.1618353128433228 val loss: 1.163283348083496\n",
      "epoch: 0 i: 309 loss: 1.1617989540100098 val loss: 1.163176417350769\n",
      "epoch: 0 i: 319 loss: 1.162245750427246 val loss: 1.1628577709197998\n",
      "epoch: 0 i: 329 loss: 1.162918210029602 val loss: 1.162608027458191\n",
      "epoch: 0 i: 339 loss: 1.1606860160827637 val loss: 1.1627905368804932\n",
      "epoch: 0 i: 349 loss: 1.1614406108856201 val loss: 1.1623872518539429\n",
      "epoch: 0 i: 359 loss: 1.1615471839904785 val loss: 1.162267804145813\n",
      "epoch: 0 i: 369 loss: 1.161376714706421 val loss: 1.1624008417129517\n",
      "epoch: 0 i: 379 loss: 1.161708116531372 val loss: 1.16227126121521\n",
      "epoch: 0 i: 389 loss: 1.1618945598602295 val loss: 1.1619975566864014\n",
      "epoch: 0 i: 399 loss: 1.1615285873413086 val loss: 1.1618120670318604\n",
      "epoch: 0 i: 409 loss: 1.1617096662521362 val loss: 1.1616755723953247\n",
      "epoch: 0 i: 419 loss: 1.1610639095306396 val loss: 1.1616677045822144\n",
      "epoch: 0 i: 429 loss: 1.1616445779800415 val loss: 1.161353588104248\n",
      "epoch: 0 i: 439 loss: 1.1606074571609497 val loss: 1.161262035369873\n",
      "epoch: 0 i: 449 loss: 1.1603041887283325 val loss: 1.161185383796692\n",
      "epoch: 0 i: 459 loss: 1.1611714363098145 val loss: 1.1612778902053833\n",
      "epoch: 0 i: 469 loss: 1.1606866121292114 val loss: 1.161464810371399\n",
      "epoch: 0 i: 479 loss: 1.1599938869476318 val loss: 1.1610559225082397\n",
      "epoch: 0 i: 489 loss: 1.1604785919189453 val loss: 1.161104679107666\n",
      "epoch: 0 i: 499 loss: 1.160439372062683 val loss: 1.1608229875564575\n",
      "epoch: 0 i: 509 loss: 1.1607023477554321 val loss: 1.160852074623108\n",
      "epoch: 0 i: 519 loss: 1.160248875617981 val loss: 1.1607269048690796\n",
      "epoch: 0 i: 529 loss: 1.1611354351043701 val loss: 1.160565972328186\n",
      "epoch: 0 i: 539 loss: 1.1606470346450806 val loss: 1.1602702140808105\n",
      "epoch: 0 i: 549 loss: 1.1599540710449219 val loss: 1.1604454517364502\n",
      "epoch: 0 i: 559 loss: 1.1605974435806274 val loss: 1.1606128215789795\n",
      "epoch: 0 i: 569 loss: 1.1610100269317627 val loss: 1.1600172519683838\n",
      "epoch: 0 i: 579 loss: 1.1598082780838013 val loss: 1.1606262922286987\n",
      "epoch: 0 i: 589 loss: 1.1599959135055542 val loss: 1.1612398624420166\n",
      "epoch: 0 i: 599 loss: 1.1603150367736816 val loss: 1.1609673500061035\n",
      "epoch: 1 i: 9 loss: 1.1598409414291382 val loss: 1.1602462530136108\n",
      "epoch: 1 i: 19 loss: 1.15988290309906 val loss: 1.1601532697677612\n",
      "epoch: 1 i: 29 loss: 1.1585562229156494 val loss: 1.159803867340088\n",
      "epoch: 1 i: 39 loss: 1.1591676473617554 val loss: 1.159764051437378\n",
      "epoch: 1 i: 49 loss: 1.1588108539581299 val loss: 1.1593306064605713\n",
      "epoch: 1 i: 59 loss: 1.1592581272125244 val loss: 1.1594629287719727\n",
      "epoch: 1 i: 69 loss: 1.158602237701416 val loss: 1.159256935119629\n",
      "epoch: 1 i: 79 loss: 1.1600981950759888 val loss: 1.1593427658081055\n",
      "epoch: 1 i: 89 loss: 1.1584579944610596 val loss: 1.1591626405715942\n",
      "epoch: 1 i: 99 loss: 1.159035563468933 val loss: 1.1588348150253296\n",
      "epoch: 1 i: 109 loss: 1.159061312675476 val loss: 1.1591005325317383\n",
      "epoch: 1 i: 119 loss: 1.1588417291641235 val loss: 1.1588609218597412\n",
      "epoch: 1 i: 129 loss: 1.1595298051834106 val loss: 1.1589899063110352\n",
      "epoch: 1 i: 139 loss: 1.159820318222046 val loss: 1.1590150594711304\n",
      "epoch: 1 i: 149 loss: 1.1577414274215698 val loss: 1.1588621139526367\n",
      "epoch: 1 i: 159 loss: 1.1589964628219604 val loss: 1.1588001251220703\n",
      "epoch: 1 i: 169 loss: 1.1578840017318726 val loss: 1.1584689617156982\n",
      "epoch: 1 i: 179 loss: 1.1588058471679688 val loss: 1.1584125757217407\n",
      "epoch: 1 i: 189 loss: 1.1580604314804077 val loss: 1.158370018005371\n",
      "epoch: 1 i: 199 loss: 1.159712553024292 val loss: 1.158146619796753\n",
      "epoch: 1 i: 209 loss: 1.1584869623184204 val loss: 1.1581276655197144\n",
      "epoch: 1 i: 219 loss: 1.1586663722991943 val loss: 1.1579604148864746\n",
      "epoch: 1 i: 229 loss: 1.15792977809906 val loss: 1.1580091714859009\n",
      "epoch: 1 i: 239 loss: 1.157694697380066 val loss: 1.1579967737197876\n",
      "epoch: 1 i: 249 loss: 1.1567267179489136 val loss: 1.157598853111267\n",
      "epoch: 1 i: 259 loss: 1.1575349569320679 val loss: 1.1574851274490356\n",
      "epoch: 1 i: 269 loss: 1.1571720838546753 val loss: 1.1572957038879395\n",
      "epoch: 1 i: 279 loss: 1.157612919807434 val loss: 1.1582701206207275\n",
      "epoch: 1 i: 289 loss: 1.158600091934204 val loss: 1.1574777364730835\n",
      "epoch: 1 i: 299 loss: 1.156671404838562 val loss: 1.1574280261993408\n",
      "epoch: 1 i: 309 loss: 1.156538963317871 val loss: 1.1570786237716675\n",
      "epoch: 1 i: 319 loss: 1.156839370727539 val loss: 1.157151460647583\n",
      "epoch: 1 i: 329 loss: 1.1574212312698364 val loss: 1.1569191217422485\n",
      "epoch: 1 i: 339 loss: 1.1559009552001953 val loss: 1.1571305990219116\n",
      "epoch: 1 i: 349 loss: 1.1566962003707886 val loss: 1.1567869186401367\n",
      "epoch: 1 i: 359 loss: 1.156636118888855 val loss: 1.156731128692627\n",
      "epoch: 1 i: 369 loss: 1.1563702821731567 val loss: 1.156847596168518\n",
      "epoch: 1 i: 379 loss: 1.1565920114517212 val loss: 1.1569085121154785\n",
      "epoch: 1 i: 389 loss: 1.1564750671386719 val loss: 1.156434416770935\n",
      "epoch: 1 i: 399 loss: 1.1563795804977417 val loss: 1.1564445495605469\n",
      "epoch: 1 i: 409 loss: 1.1564537286758423 val loss: 1.156356930732727\n",
      "epoch: 1 i: 419 loss: 1.1562283039093018 val loss: 1.156354308128357\n",
      "epoch: 1 i: 429 loss: 1.1562979221343994 val loss: 1.1563187837600708\n",
      "epoch: 1 i: 439 loss: 1.1559133529663086 val loss: 1.1563396453857422\n",
      "epoch: 1 i: 449 loss: 1.1555110216140747 val loss: 1.1560497283935547\n",
      "epoch: 1 i: 459 loss: 1.1559844017028809 val loss: 1.1560331583023071\n",
      "epoch: 1 i: 469 loss: 1.1555827856063843 val loss: 1.1561509370803833\n",
      "epoch: 1 i: 479 loss: 1.1554477214813232 val loss: 1.1559442281723022\n",
      "epoch: 1 i: 489 loss: 1.1557328701019287 val loss: 1.1558952331542969\n",
      "epoch: 1 i: 499 loss: 1.1556755304336548 val loss: 1.155888319015503\n",
      "epoch: 1 i: 509 loss: 1.1558630466461182 val loss: 1.1558396816253662\n",
      "epoch: 1 i: 519 loss: 1.155657172203064 val loss: 1.155695915222168\n",
      "epoch: 1 i: 529 loss: 1.156211018562317 val loss: 1.155559778213501\n",
      "epoch: 1 i: 539 loss: 1.1558963060379028 val loss: 1.1553821563720703\n",
      "epoch: 1 i: 549 loss: 1.1552362442016602 val loss: 1.155447006225586\n",
      "epoch: 1 i: 559 loss: 1.1556334495544434 val loss: 1.1555181741714478\n",
      "epoch: 1 i: 569 loss: 1.1560249328613281 val loss: 1.1552163362503052\n",
      "epoch: 1 i: 579 loss: 1.1552845239639282 val loss: 1.1553937196731567\n",
      "epoch: 1 i: 589 loss: 1.1549346446990967 val loss: 1.1558436155319214\n",
      "epoch: 1 i: 599 loss: 1.1552608013153076 val loss: 1.1559228897094727\n",
      "epoch: 2 i: 9 loss: 1.1553058624267578 val loss: 1.155385971069336\n",
      "epoch: 2 i: 19 loss: 1.1550830602645874 val loss: 1.1553066968917847\n",
      "epoch: 2 i: 29 loss: 1.1544275283813477 val loss: 1.1550583839416504\n",
      "epoch: 2 i: 39 loss: 1.1548008918762207 val loss: 1.154936671257019\n",
      "epoch: 2 i: 49 loss: 1.1543653011322021 val loss: 1.1549848318099976\n",
      "epoch: 2 i: 59 loss: 1.155089020729065 val loss: 1.1549876928329468\n",
      "epoch: 2 i: 69 loss: 1.1545227766036987 val loss: 1.1549118757247925\n",
      "epoch: 2 i: 79 loss: 1.1552956104278564 val loss: 1.1549445390701294\n"
     ]
    }
   ],
   "source": [
    "pixelCNN.train(True)\n",
    "EPOCH = 30\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "j = 0\n",
    "for epoch in range(EPOCH):\n",
    "  pixelCNN.train()\n",
    "  for i, labels in enumerate(trainloader, 0):\n",
    "    labels = labels.to(device)\n",
    "    # print(\"Labels:\", labels.shape)\n",
    "   \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = pixelCNN(labels.float())\n",
    "    # print(\"Outout:\", outputs.shape)\n",
    "    loss = criterion(outputs, labels.long())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss = loss.item()\n",
    "    # print statistics\n",
    "    j += 1 \n",
    "    if ((i+1) % 10 == 0):\n",
    "      with torch.set_grad_enabled(False):\n",
    "        val_batch = next(iter(testloader))\n",
    "        val_batch = val_batch.to(device)\n",
    "\n",
    "        val_output = pixelCNN(val_batch.float())\n",
    "        val_loss_item = criterion(val_output, val_batch.long()).item()\n",
    "        val_loss.append(val_loss_item)\n",
    "      print(\"epoch:\", epoch, \"i:\" , i, \"loss:\", loss, \"val loss:\", val_loss_item)\n",
    "    train_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_bf8bFQzNb5"
   },
   "outputs": [],
   "source": [
    "print(\"Train loss: \")\n",
    "plt.plot(train_loss, label = \"train_loss\")\n",
    "plt.plot(np.arange(0, len(train_loss),int(len(train_loss)/len(val_loss))),val_loss, label = \"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UNoj9L6spMZ"
   },
   "outputs": [],
   "source": [
    "torch.save(pixelCNN.state_dict(), 'drive/My Drive/Colab Notebooks/pixel_cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-uk12A9aFzP"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-de575c129489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpixelCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPixelCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpixelCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pixel_cnn_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'encoding'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    116\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "pixelCNN = PixelCNN().to(device)\n",
    "pixelCNN.load_state_dict(torch.load('pixel_cnn_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-uFdbF_UjXMb"
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "image = torch.Tensor(np.random.choice(4, size=(batch_size, 3, 28, 28))).type(torch.FloatTensor).cuda()\n",
    "\n",
    "for k in range(3):   \n",
    "  for i in range(28):\n",
    "    for j in range(28):\n",
    "      # in_tensor = torch.from_numpy(image).float()\n",
    "      # in_tensor = in_tensor.to(device)\n",
    "      out = pixelCNN(image).permute(0, 4, 3, 2, 1)\n",
    "      probs = torch.nn.functional.softmax(out, dim=-1)\n",
    "      probs = torch.argmax(probs, dim=-1).permute(0,3,1,2)\n",
    "      image[:, k, i, j] = probs[:, k, i, j]\n",
    "      # probs = probs.to(\"cpu\").detach().numpy()      \n",
    "      # for b in range(batch_size):\n",
    "      #   image[b, k, i, j] = np.random.choice(4, p=probs[b, k, i, j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDNM9st-jW8O"
   },
   "outputs": [],
   "source": [
    "# Saving\n",
    "torchvision.utils.save_image(torch.from_numpy(image), 'drive/My Drive/Colab Notebooks/sample.png', nrow=10, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "faSDMzxDjW3o"
   },
   "outputs": [],
   "source": [
    "image = image.cpu().detach().numpy()    \n",
    "image = image * 256 / 3\n",
    "fig, axs = plt.subplots(10, 5, figsize=(20, 50))\n",
    "count = 0\n",
    "\n",
    "for i in range(5):\n",
    "  for j in range(10):\n",
    "    temp_image = image[count,:,:,:].astype(int)\n",
    "    count += 1\n",
    "    axs[j][i].imshow(temp_image.reshape(28,28,3))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ke7oyHQELOz7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEKIyRE1jWwT"
   },
   "outputs": [],
   "source": [
    "image = torch.Tensor(np.random.choice(4, size=(1, 3, 28, 28))).type(torch.FloatTensor).cuda()\n",
    "out = pixelCNN(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TCojeuHsjWKM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "exercise02.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
