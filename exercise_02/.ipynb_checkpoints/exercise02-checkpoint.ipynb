{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7f2UGEYiWjH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import pickle\n",
    "\n",
    "\n",
    "import matplotlib.pyplot  as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yNQLvG7YihTk",
    "outputId": "2201b61c-fdc0-40a4-9a9b-2cb75f77e0b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVc-FD4wiiPm"
   },
   "outputs": [],
   "source": [
    "with open('drive/My Drive/Colab Notebooks/colored-mnist.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbpAsNW0iiS0"
   },
   "outputs": [],
   "source": [
    "train = data['train']\n",
    "test = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "7yACKEVPiiWU",
    "outputId": "67c514d9-c0a3-47ba-f4e9-9b2a89c556b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count train samples:  60000\n",
      "Count test samples:  10000\n",
      "Shape of image (H, W, C):  (28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Count train samples: \", train.shape[0])\n",
    "print(\"Count test samples: \", test.shape[0])\n",
    "print(\"Shape of image (H, W, C): \", train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "mkIyxgunAOkw",
    "outputId": "80227b8e-68d2-464c-c653-ca681bbfa860"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAACaCAYAAABmDna+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niPT/brNIOkF4TJUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "def show_image(i, image): \n",
    "  print_image =  image * (256 / 3)\n",
    "  fig.add_subplot(1, 4, i+1)\n",
    "  plt.imshow(print_image.astype(int))\n",
    "  \n",
    "\n",
    "for i in range(0, 4):\n",
    "  show_image(i, train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZblPjcNe-9iI"
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, target, transform=None):\n",
    "      self.target = torch.from_numpy(target).view(-1, 3, 28, 28)\n",
    "      self.transform = transform\n",
    "      \n",
    "  def __getitem__(self, index):\n",
    "      y = self.target[index]\n",
    "      \n",
    "      if self.transform:\n",
    "          y = self.transform(y)\n",
    "          \n",
    "      return y\n",
    "  \n",
    "  def __len__(self):\n",
    "      return len(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udbU4oDE_DxO"
   },
   "outputs": [],
   "source": [
    "BATCHSIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_x1ZITM_CN8"
   },
   "outputs": [],
   "source": [
    "train_ds = MyDataset(train)\n",
    "test_ds = MyDataset(test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=BATCHSIZE)\n",
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kKwBHSvWTgTJ",
    "outputId": "f735a1d6-431b-457e-97c0-ac59470a6141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape:  torch.Size([50, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "labels = dataiter.next()\n",
    "print(\"Tensor shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qr3-rgT0Tgv4"
   },
   "source": [
    "## Masking\n",
    "\n",
    "- ConvLayer 7x7 needs Mask A\n",
    "\n",
    "- The Convlayers in the residual Blocks need the Mask B \n",
    "\n",
    "\n",
    "### Example for 3x3 Filter\n",
    "- Mask A:\n",
    "$\\left( \\begin{array}{rrr}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{array}\\right) $\n",
    "\n",
    "- Mask B:\n",
    "$\\left( \\begin{array}{rrr}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{array}\\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULnS0vdKlLSl"
   },
   "outputs": [],
   "source": [
    "# Quelle: https://www.codeproject.com/Articles/5061271/PixelCNN-in-Autoregressive-Models\n",
    "class MaskedConv2d(torch.nn.Conv2d):\n",
    "  def __init__(self, mask_type, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    assert mask_type in ('A', 'B')\n",
    "    self.register_buffer('mask', self.weight.data.clone())\n",
    "    _, _, fH, fW = self.weight.size()\n",
    "    \n",
    "    self.mask.fill_(1)\n",
    "    if (mask_type == 'B'): \n",
    "      self.mask[:, :, fH // 2, fW // 2 + 1:] = 0\n",
    "    else:\n",
    "      self.mask[:, :, fH // 2, fW // 2:] = 0\n",
    "    \n",
    "    self.mask[:, :, fH // 2 + 1:] = 0\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.weight.data *= self.mask\n",
    "    return super(MaskedConv2d, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPLZeWQblLV8"
   },
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, channels=128):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.channels=channels\n",
    "\n",
    "    self.network = torch.nn.Sequential(\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(self.channels*2,self.channels, 1, stride=1, padding=0), \n",
    "        torch.nn.BatchNorm2d(self.channels), \n",
    "        torch.nn.ReLU(),\n",
    "        MaskedConv2d('B',self.channels, self.channels, 3, stride=1, padding=1),\n",
    "        torch.nn.BatchNorm2d(self.channels), \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(self.channels,self.channels*2, 1, stride=1, padding=0),\n",
    "        torch.nn.BatchNorm2d(2*self.channels)\n",
    "      )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out= self.network(x)\n",
    "    return x + out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWSPjoPklLY6"
   },
   "outputs": [],
   "source": [
    "class PixelCNN(torch.nn.Module):\n",
    "    \n",
    "  def __init__(self, channels=128, res_blocks=12): \n",
    "    super(PixelCNN,self).__init__()\n",
    "    layers = []\n",
    "    layers.append(MaskedConv2d(\"A\", 3, channels*2, 7, padding=3))\n",
    "\n",
    "    for i in range(res_blocks):\n",
    "      layers.append(ResBlock(channels))\n",
    "\n",
    "    layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Conv2d(channels*2, 1024, 1, 1, 0))\n",
    "    layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Conv2d(1024, 3*4, 1, 1, 0))\n",
    "    # layers.append(torch.nn.Softmax())\n",
    "\n",
    "    self.network = torch.nn.Sequential(*layers)\n",
    "   \n",
    "  def forward(self, x):\n",
    "    out = self.network(x)\n",
    "    return out.view(-1,4,3,28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okFtCy5GlLbq"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pixelCNN = PixelCNN(128).to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  pixelCNN = torch.nn.DataParallel(pixelCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "my1aMqqcQ1XX"
   },
   "outputs": [],
   "source": [
    "# pixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zCd10d9owmqR",
    "outputId": "c317f86b-06e7-437a-a122-2c7a74b64190"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_F2HkkAiiZ6"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pixelCNN.parameters(),lr=3e-4, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UoREGLUX2YtC",
    "outputId": "8329243c-d03c-4395-fa1f-f301c73ed650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 i: 9 loss: 0.6097365021705627\n",
      "epoch: 0 i: 19 loss: 0.4618673026561737\n",
      "epoch: 0 i: 29 loss: 0.3777463436126709\n",
      "epoch: 0 i: 39 loss: 0.3303174376487732\n",
      "epoch: 0 i: 49 loss: 0.30400532484054565\n",
      "epoch: 0 i: 59 loss: 0.25209298729896545\n",
      "epoch: 0 i: 69 loss: 0.2779010236263275\n",
      "epoch: 0 i: 79 loss: 0.24561356008052826\n",
      "epoch: 0 i: 89 loss: 0.2339337319135666\n",
      "epoch: 0 i: 99 loss: 0.2315782904624939\n",
      "epoch: 0 i: 109 loss: 0.23763981461524963\n",
      "epoch: 0 i: 119 loss: 0.22943764925003052\n",
      "epoch: 0 i: 129 loss: 0.21802741289138794\n",
      "epoch: 0 i: 139 loss: 0.20978400111198425\n",
      "epoch: 0 i: 149 loss: 0.21776506304740906\n",
      "epoch: 0 i: 159 loss: 0.2157430797815323\n",
      "epoch: 0 i: 169 loss: 0.20579028129577637\n",
      "epoch: 0 i: 179 loss: 0.20209166407585144\n",
      "epoch: 0 i: 189 loss: 0.21172940731048584\n",
      "epoch: 0 i: 199 loss: 0.22160932421684265\n",
      "epoch: 0 i: 209 loss: 0.21866554021835327\n",
      "epoch: 0 i: 219 loss: 0.19227167963981628\n",
      "epoch: 0 i: 229 loss: 0.2116352766752243\n",
      "epoch: 0 i: 239 loss: 0.2119831144809723\n",
      "epoch: 0 i: 249 loss: 0.19346186518669128\n",
      "epoch: 0 i: 259 loss: 0.2171488255262375\n",
      "epoch: 0 i: 269 loss: 0.20671328902244568\n",
      "epoch: 0 i: 279 loss: 0.21315331757068634\n",
      "epoch: 0 i: 289 loss: 0.19284909963607788\n",
      "epoch: 0 i: 299 loss: 0.18531547486782074\n",
      "epoch: 0 i: 309 loss: 0.18905502557754517\n",
      "epoch: 0 i: 319 loss: 0.19440174102783203\n",
      "epoch: 0 i: 329 loss: 0.20583580434322357\n",
      "epoch: 0 i: 339 loss: 0.1877942681312561\n",
      "epoch: 0 i: 349 loss: 0.1994730830192566\n",
      "epoch: 0 i: 359 loss: 0.19483469426631927\n",
      "epoch: 0 i: 369 loss: 0.17824241518974304\n",
      "epoch: 0 i: 379 loss: 0.18176817893981934\n",
      "epoch: 0 i: 389 loss: 0.18687596917152405\n",
      "epoch: 0 i: 399 loss: 0.18517224490642548\n",
      "epoch: 0 i: 409 loss: 0.18308402597904205\n",
      "epoch: 0 i: 419 loss: 0.18239466845989227\n",
      "epoch: 0 i: 429 loss: 0.1807927042245865\n",
      "epoch: 0 i: 439 loss: 0.18026669323444366\n",
      "epoch: 0 i: 449 loss: 0.1704135537147522\n",
      "epoch: 0 i: 459 loss: 0.17216065526008606\n",
      "epoch: 0 i: 469 loss: 0.19616879522800446\n",
      "epoch: 0 i: 479 loss: 0.1683175265789032\n",
      "epoch: 0 i: 489 loss: 0.18215037882328033\n",
      "epoch: 0 i: 499 loss: 0.17636851966381073\n",
      "epoch: 0 i: 509 loss: 0.17737922072410583\n",
      "epoch: 0 i: 519 loss: 0.17906954884529114\n",
      "epoch: 0 i: 529 loss: 0.17363640666007996\n",
      "epoch: 0 i: 539 loss: 0.16557839512825012\n",
      "epoch: 0 i: 549 loss: 0.1750842183828354\n",
      "epoch: 0 i: 559 loss: 0.16666996479034424\n",
      "epoch: 0 i: 569 loss: 0.16199716925621033\n",
      "epoch: 0 i: 579 loss: 0.17973417043685913\n",
      "epoch: 0 i: 589 loss: 0.16528300940990448\n",
      "epoch: 0 i: 599 loss: 0.1561177521944046\n",
      "epoch: 0 i: 609 loss: 0.16181299090385437\n",
      "epoch: 0 i: 619 loss: 0.16054244339466095\n",
      "epoch: 0 i: 629 loss: 0.18196722865104675\n",
      "epoch: 0 i: 639 loss: 0.15582375228405\n",
      "epoch: 0 i: 649 loss: 0.1674492508172989\n",
      "epoch: 0 i: 659 loss: 0.1635119765996933\n",
      "epoch: 0 i: 669 loss: 0.15455234050750732\n",
      "epoch: 0 i: 679 loss: 0.15285342931747437\n",
      "epoch: 0 i: 689 loss: 0.15856552124023438\n",
      "epoch: 0 i: 699 loss: 0.14905394613742828\n",
      "epoch: 0 i: 709 loss: 0.17319227755069733\n",
      "epoch: 0 i: 719 loss: 0.15327323973178864\n",
      "epoch: 0 i: 729 loss: 0.15550492703914642\n",
      "epoch: 0 i: 739 loss: 0.1469458043575287\n",
      "epoch: 0 i: 749 loss: 0.14424175024032593\n",
      "epoch: 0 i: 759 loss: 0.1476081907749176\n",
      "epoch: 0 i: 769 loss: 0.138732448220253\n",
      "epoch: 0 i: 779 loss: 0.14177170395851135\n",
      "epoch: 0 i: 789 loss: 0.14386679232120514\n",
      "epoch: 0 i: 799 loss: 0.1402830183506012\n",
      "epoch: 0 i: 809 loss: 0.1468937247991562\n",
      "epoch: 0 i: 819 loss: 0.1355200856924057\n",
      "epoch: 0 i: 829 loss: 0.13688789308071136\n",
      "epoch: 0 i: 839 loss: 0.13183027505874634\n",
      "epoch: 0 i: 849 loss: 0.13492195308208466\n",
      "epoch: 0 i: 859 loss: 0.13247327506542206\n",
      "epoch: 0 i: 869 loss: 0.12910406291484833\n",
      "epoch: 0 i: 879 loss: 0.12783890962600708\n",
      "epoch: 0 i: 889 loss: 0.1265580803155899\n",
      "epoch: 0 i: 899 loss: 0.11833535134792328\n",
      "epoch: 0 i: 909 loss: 0.1301230788230896\n",
      "epoch: 0 i: 919 loss: 0.1295125037431717\n",
      "epoch: 0 i: 929 loss: 0.12053527683019638\n",
      "epoch: 0 i: 939 loss: 0.12393268197774887\n",
      "epoch: 0 i: 949 loss: 0.1270487755537033\n",
      "epoch: 0 i: 959 loss: 0.11404450982809067\n",
      "epoch: 0 i: 969 loss: 0.11074838042259216\n",
      "epoch: 0 i: 979 loss: 0.11238747835159302\n",
      "epoch: 0 i: 989 loss: 0.11376852542161942\n",
      "epoch: 0 i: 999 loss: 0.11554333567619324\n",
      "epoch: 0 i: 1009 loss: 0.11410456150770187\n",
      "epoch: 0 i: 1019 loss: 0.11953908950090408\n",
      "epoch: 0 i: 1029 loss: 0.11532971262931824\n",
      "epoch: 0 i: 1039 loss: 0.11397005617618561\n",
      "epoch: 0 i: 1049 loss: 0.09886400401592255\n",
      "epoch: 0 i: 1059 loss: 0.1040310338139534\n",
      "epoch: 0 i: 1069 loss: 0.10019838809967041\n",
      "epoch: 0 i: 1079 loss: 0.10868687182664871\n",
      "epoch: 0 i: 1089 loss: 0.10171995311975479\n",
      "epoch: 0 i: 1099 loss: 0.10231985151767731\n",
      "epoch: 0 i: 1109 loss: 0.09464893490076065\n",
      "epoch: 0 i: 1119 loss: 0.09565775096416473\n",
      "epoch: 0 i: 1129 loss: 0.10273276269435883\n",
      "epoch: 0 i: 1139 loss: 0.10434959828853607\n",
      "epoch: 0 i: 1149 loss: 0.10304923355579376\n",
      "epoch: 0 i: 1159 loss: 0.09593590348958969\n",
      "epoch: 0 i: 1169 loss: 0.10046335309743881\n",
      "epoch: 0 i: 1179 loss: 0.09162526577711105\n",
      "epoch: 0 i: 1189 loss: 0.10420732945203781\n",
      "epoch: 0 i: 1199 loss: 0.10136687010526657\n",
      "epoch: 1 i: 9 loss: 0.0976666584610939\n",
      "epoch: 1 i: 19 loss: 0.09026964008808136\n",
      "epoch: 1 i: 29 loss: 0.09621525555849075\n",
      "epoch: 1 i: 39 loss: 0.09022695571184158\n",
      "epoch: 1 i: 49 loss: 0.09001447260379791\n",
      "epoch: 1 i: 59 loss: 0.08335649222135544\n",
      "epoch: 1 i: 69 loss: 0.08296837657690048\n",
      "epoch: 1 i: 79 loss: 0.0853513702750206\n",
      "epoch: 1 i: 89 loss: 0.08466984331607819\n",
      "epoch: 1 i: 99 loss: 0.08350135385990143\n",
      "epoch: 1 i: 109 loss: 0.08570174127817154\n",
      "epoch: 1 i: 119 loss: 0.08458948880434036\n",
      "epoch: 1 i: 129 loss: 0.08369971066713333\n",
      "epoch: 1 i: 139 loss: 0.08054205030202866\n",
      "epoch: 1 i: 149 loss: 0.08388549089431763\n",
      "epoch: 1 i: 159 loss: 0.08203627169132233\n",
      "epoch: 1 i: 169 loss: 0.07845935970544815\n",
      "epoch: 1 i: 179 loss: 0.07793307304382324\n",
      "epoch: 1 i: 189 loss: 0.08628703653812408\n",
      "epoch: 1 i: 199 loss: 0.08654702454805374\n",
      "epoch: 1 i: 209 loss: 0.08727751672267914\n",
      "epoch: 1 i: 219 loss: 0.079000324010849\n",
      "epoch: 1 i: 229 loss: 0.08147507160902023\n",
      "epoch: 1 i: 239 loss: 0.07970596104860306\n",
      "epoch: 1 i: 249 loss: 0.07961732149124146\n",
      "epoch: 1 i: 259 loss: 0.0853867307305336\n",
      "epoch: 1 i: 269 loss: 0.08310079574584961\n",
      "epoch: 1 i: 279 loss: 0.08763299882411957\n",
      "epoch: 1 i: 289 loss: 0.08176225423812866\n",
      "epoch: 1 i: 299 loss: 0.07324942201375961\n",
      "epoch: 1 i: 309 loss: 0.07574951648712158\n",
      "epoch: 1 i: 319 loss: 0.07496625930070877\n",
      "epoch: 1 i: 329 loss: 0.07973113656044006\n",
      "epoch: 1 i: 339 loss: 0.07444445043802261\n",
      "epoch: 1 i: 349 loss: 0.08137944340705872\n",
      "epoch: 1 i: 359 loss: 0.0785309225320816\n",
      "epoch: 1 i: 369 loss: 0.0741107240319252\n",
      "epoch: 1 i: 379 loss: 0.07408186793327332\n",
      "epoch: 1 i: 389 loss: 0.07713185995817184\n",
      "epoch: 1 i: 399 loss: 0.08140183985233307\n",
      "epoch: 1 i: 409 loss: 0.07403557747602463\n",
      "epoch: 1 i: 419 loss: 0.07583164423704147\n",
      "epoch: 1 i: 429 loss: 0.07576730847358704\n",
      "epoch: 1 i: 439 loss: 0.07560547441244125\n",
      "epoch: 1 i: 449 loss: 0.07300178706645966\n",
      "epoch: 1 i: 459 loss: 0.07693266123533249\n",
      "epoch: 1 i: 469 loss: 0.07381214946508408\n",
      "epoch: 1 i: 479 loss: 0.0719108134508133\n",
      "epoch: 1 i: 489 loss: 0.08116210252046585\n",
      "epoch: 1 i: 499 loss: 0.07362841069698334\n",
      "epoch: 1 i: 509 loss: 0.07271280884742737\n",
      "epoch: 1 i: 519 loss: 0.07826274633407593\n",
      "epoch: 1 i: 529 loss: 0.07438762485980988\n",
      "epoch: 1 i: 539 loss: 0.07071182876825333\n",
      "epoch: 1 i: 549 loss: 0.07387842983007431\n",
      "epoch: 1 i: 559 loss: 0.07241188734769821\n",
      "epoch: 1 i: 569 loss: 0.07426784932613373\n",
      "epoch: 1 i: 579 loss: 0.07689610868692398\n",
      "epoch: 1 i: 589 loss: 0.07098834961652756\n",
      "epoch: 1 i: 599 loss: 0.07101652026176453\n",
      "epoch: 1 i: 609 loss: 0.07315102219581604\n",
      "epoch: 1 i: 619 loss: 0.07268330454826355\n",
      "epoch: 1 i: 629 loss: 0.0758533775806427\n",
      "epoch: 1 i: 639 loss: 0.07275723665952682\n",
      "epoch: 1 i: 649 loss: 0.07064781337976456\n",
      "epoch: 1 i: 659 loss: 0.0744745209813118\n",
      "epoch: 1 i: 669 loss: 0.07165681570768356\n",
      "epoch: 1 i: 679 loss: 0.07042817771434784\n",
      "epoch: 1 i: 689 loss: 0.07239682227373123\n",
      "epoch: 1 i: 699 loss: 0.06740953773260117\n",
      "epoch: 1 i: 709 loss: 0.07559000700712204\n",
      "epoch: 1 i: 719 loss: 0.07188904285430908\n",
      "epoch: 1 i: 729 loss: 0.07480384409427643\n",
      "epoch: 1 i: 739 loss: 0.07117941230535507\n",
      "epoch: 1 i: 749 loss: 0.06862539798021317\n",
      "epoch: 1 i: 759 loss: 0.06956276297569275\n",
      "epoch: 1 i: 769 loss: 0.06833574175834656\n",
      "epoch: 1 i: 779 loss: 0.07045706361532211\n",
      "epoch: 1 i: 789 loss: 0.06829337030649185\n",
      "epoch: 1 i: 799 loss: 0.06775028258562088\n",
      "epoch: 1 i: 809 loss: 0.07149362564086914\n",
      "epoch: 1 i: 819 loss: 0.06755765527486801\n",
      "epoch: 1 i: 829 loss: 0.0676252692937851\n",
      "epoch: 1 i: 839 loss: 0.0686483085155487\n",
      "epoch: 1 i: 849 loss: 0.07006209343671799\n",
      "epoch: 1 i: 859 loss: 0.06952840089797974\n",
      "epoch: 1 i: 869 loss: 0.06658164411783218\n",
      "epoch: 1 i: 879 loss: 0.06621407717466354\n",
      "epoch: 1 i: 889 loss: 0.06734972447156906\n",
      "epoch: 1 i: 899 loss: 0.0635056123137474\n",
      "epoch: 1 i: 909 loss: 0.07159450650215149\n",
      "epoch: 1 i: 919 loss: 0.07136040925979614\n",
      "epoch: 1 i: 929 loss: 0.06645200401544571\n",
      "epoch: 1 i: 939 loss: 0.06918403506278992\n",
      "epoch: 1 i: 949 loss: 0.07028072327375412\n",
      "epoch: 1 i: 959 loss: 0.06645513325929642\n",
      "epoch: 1 i: 969 loss: 0.06450949609279633\n",
      "epoch: 1 i: 979 loss: 0.06697146594524384\n",
      "epoch: 1 i: 989 loss: 0.07087507843971252\n",
      "epoch: 1 i: 999 loss: 0.068881556391716\n",
      "epoch: 1 i: 1009 loss: 0.06776423752307892\n",
      "epoch: 1 i: 1019 loss: 0.06935828179121017\n",
      "epoch: 1 i: 1029 loss: 0.07015229761600494\n",
      "epoch: 1 i: 1039 loss: 0.07146980613470078\n",
      "epoch: 1 i: 1049 loss: 0.06215646490454674\n",
      "epoch: 1 i: 1059 loss: 0.06552151590585709\n",
      "epoch: 1 i: 1069 loss: 0.0642748549580574\n",
      "epoch: 1 i: 1079 loss: 0.07001268118619919\n",
      "epoch: 1 i: 1089 loss: 0.06649723649024963\n",
      "epoch: 1 i: 1099 loss: 0.06961540877819061\n",
      "epoch: 1 i: 1109 loss: 0.0652480497956276\n",
      "epoch: 1 i: 1119 loss: 0.06396406143903732\n",
      "epoch: 1 i: 1129 loss: 0.0681896060705185\n",
      "epoch: 1 i: 1139 loss: 0.0666840597987175\n",
      "epoch: 1 i: 1149 loss: 0.06671159714460373\n",
      "epoch: 1 i: 1159 loss: 0.06385040283203125\n",
      "epoch: 1 i: 1169 loss: 0.0668252557516098\n",
      "epoch: 1 i: 1179 loss: 0.06426256150007248\n",
      "epoch: 1 i: 1189 loss: 0.07100485265254974\n",
      "epoch: 1 i: 1199 loss: 0.07258663326501846\n",
      "epoch: 2 i: 9 loss: 0.06880800426006317\n",
      "epoch: 2 i: 19 loss: 0.06737533211708069\n",
      "epoch: 2 i: 29 loss: 0.06689510494470596\n",
      "epoch: 2 i: 39 loss: 0.06439920514822006\n",
      "epoch: 2 i: 49 loss: 0.06481704115867615\n",
      "epoch: 2 i: 59 loss: 0.061554715037345886\n",
      "epoch: 2 i: 69 loss: 0.0602816604077816\n",
      "epoch: 2 i: 79 loss: 0.06513313949108124\n",
      "epoch: 2 i: 89 loss: 0.06446248292922974\n",
      "epoch: 2 i: 99 loss: 0.06179313361644745\n",
      "epoch: 2 i: 109 loss: 0.06292510777711868\n",
      "epoch: 2 i: 119 loss: 0.06260503083467484\n",
      "epoch: 2 i: 129 loss: 0.062432583421468735\n",
      "epoch: 2 i: 139 loss: 0.06145001947879791\n",
      "epoch: 2 i: 149 loss: 0.06449513137340546\n",
      "epoch: 2 i: 159 loss: 0.06138245388865471\n",
      "epoch: 2 i: 169 loss: 0.06001422554254532\n",
      "epoch: 2 i: 179 loss: 0.06008317321538925\n",
      "epoch: 2 i: 189 loss: 0.06406257301568985\n",
      "epoch: 2 i: 199 loss: 0.0649760439991951\n",
      "epoch: 2 i: 209 loss: 0.0662066638469696\n",
      "epoch: 2 i: 219 loss: 0.06190866604447365\n",
      "epoch: 2 i: 229 loss: 0.06327644735574722\n",
      "epoch: 2 i: 239 loss: 0.06146206334233284\n",
      "epoch: 2 i: 249 loss: 0.06303957849740982\n",
      "epoch: 2 i: 259 loss: 0.06768518686294556\n",
      "epoch: 2 i: 269 loss: 0.0635463073849678\n",
      "epoch: 2 i: 279 loss: 0.06905058026313782\n",
      "epoch: 2 i: 289 loss: 0.06520272046327591\n",
      "epoch: 2 i: 299 loss: 0.05769885703921318\n",
      "epoch: 2 i: 309 loss: 0.06088234856724739\n",
      "epoch: 2 i: 319 loss: 0.05880801007151604\n",
      "epoch: 2 i: 329 loss: 0.06352923065423965\n",
      "epoch: 2 i: 339 loss: 0.05965806543827057\n",
      "epoch: 2 i: 349 loss: 0.06348378956317902\n",
      "epoch: 2 i: 359 loss: 0.06281164288520813\n",
      "epoch: 2 i: 369 loss: 0.059883181005716324\n",
      "epoch: 2 i: 379 loss: 0.0604364313185215\n",
      "epoch: 2 i: 389 loss: 0.06136336922645569\n",
      "epoch: 2 i: 399 loss: 0.06527546793222427\n",
      "epoch: 2 i: 409 loss: 0.059740107506513596\n",
      "epoch: 2 i: 419 loss: 0.06277702003717422\n",
      "epoch: 2 i: 429 loss: 0.060602325946092606\n",
      "epoch: 2 i: 439 loss: 0.06332682818174362\n",
      "epoch: 2 i: 449 loss: 0.06242464482784271\n",
      "epoch: 2 i: 459 loss: 0.0652490109205246\n",
      "epoch: 2 i: 469 loss: 0.06117059290409088\n",
      "epoch: 2 i: 479 loss: 0.059409163892269135\n",
      "epoch: 2 i: 489 loss: 0.06578981876373291\n",
      "epoch: 2 i: 499 loss: 0.060228243470191956\n",
      "epoch: 2 i: 509 loss: 0.05944341793656349\n",
      "epoch: 2 i: 519 loss: 0.0641423761844635\n",
      "epoch: 2 i: 529 loss: 0.0630514994263649\n",
      "epoch: 2 i: 539 loss: 0.059995297342538834\n",
      "epoch: 2 i: 549 loss: 0.062123097479343414\n",
      "epoch: 2 i: 559 loss: 0.060806453227996826\n",
      "epoch: 2 i: 569 loss: 0.06331280618906021\n",
      "epoch: 2 i: 579 loss: 0.0643559917807579\n",
      "epoch: 2 i: 589 loss: 0.06039343774318695\n",
      "epoch: 2 i: 599 loss: 0.06022311747074127\n",
      "epoch: 2 i: 609 loss: 0.06301182508468628\n",
      "epoch: 2 i: 619 loss: 0.06091051921248436\n",
      "epoch: 2 i: 629 loss: 0.06379563361406326\n",
      "epoch: 2 i: 639 loss: 0.061811599880456924\n",
      "epoch: 2 i: 649 loss: 0.0598042793571949\n",
      "epoch: 2 i: 659 loss: 0.06250301748514175\n",
      "epoch: 2 i: 669 loss: 0.061385348439216614\n",
      "epoch: 2 i: 679 loss: 0.06097230687737465\n",
      "epoch: 2 i: 689 loss: 0.06182757392525673\n",
      "epoch: 2 i: 699 loss: 0.058722734451293945\n",
      "epoch: 2 i: 709 loss: 0.06497062742710114\n",
      "epoch: 2 i: 719 loss: 0.06320450454950333\n",
      "epoch: 2 i: 729 loss: 0.06503534317016602\n",
      "epoch: 2 i: 739 loss: 0.06229881942272186\n",
      "epoch: 2 i: 749 loss: 0.059310343116521835\n",
      "epoch: 2 i: 759 loss: 0.06044381111860275\n",
      "epoch: 2 i: 769 loss: 0.05801386758685112\n",
      "epoch: 2 i: 779 loss: 0.06052182614803314\n",
      "epoch: 2 i: 789 loss: 0.059009186923503876\n",
      "epoch: 2 i: 799 loss: 0.059895869344472885\n",
      "epoch: 2 i: 809 loss: 0.06215308606624603\n",
      "epoch: 2 i: 819 loss: 0.05879467353224754\n",
      "epoch: 2 i: 829 loss: 0.05929294601082802\n",
      "epoch: 2 i: 839 loss: 0.06087224930524826\n",
      "epoch: 2 i: 849 loss: 0.06199092045426369\n",
      "epoch: 2 i: 859 loss: 0.06089106574654579\n",
      "epoch: 2 i: 869 loss: 0.05886732414364815\n",
      "epoch: 2 i: 879 loss: 0.05822226032614708\n",
      "epoch: 2 i: 889 loss: 0.0592859648168087\n",
      "epoch: 2 i: 899 loss: 0.056127022951841354\n",
      "epoch: 2 i: 909 loss: 0.06312301009893417\n",
      "epoch: 2 i: 919 loss: 0.06298553198575974\n",
      "epoch: 2 i: 929 loss: 0.05814509093761444\n",
      "epoch: 2 i: 939 loss: 0.06066036596894264\n",
      "epoch: 2 i: 949 loss: 0.06168699637055397\n",
      "epoch: 2 i: 959 loss: 0.058062274008989334\n",
      "epoch: 2 i: 969 loss: 0.0571640208363533\n",
      "epoch: 2 i: 979 loss: 0.05917683243751526\n",
      "epoch: 2 i: 989 loss: 0.06344562023878098\n",
      "epoch: 2 i: 999 loss: 0.06234974041581154\n",
      "epoch: 2 i: 1009 loss: 0.06050621345639229\n",
      "epoch: 2 i: 1019 loss: 0.06232954561710358\n",
      "epoch: 2 i: 1029 loss: 0.0621696375310421\n",
      "epoch: 2 i: 1039 loss: 0.06494660675525665\n",
      "epoch: 2 i: 1049 loss: 0.05634041503071785\n",
      "epoch: 2 i: 1059 loss: 0.05922504514455795\n",
      "epoch: 2 i: 1069 loss: 0.058729659765958786\n",
      "epoch: 2 i: 1079 loss: 0.06418881565332413\n",
      "epoch: 2 i: 1089 loss: 0.059268079698085785\n",
      "epoch: 2 i: 1099 loss: 0.06264525651931763\n",
      "epoch: 2 i: 1109 loss: 0.058852456510066986\n",
      "epoch: 2 i: 1119 loss: 0.057922448962926865\n",
      "epoch: 2 i: 1129 loss: 0.06098989397287369\n",
      "epoch: 2 i: 1139 loss: 0.05924038589000702\n",
      "epoch: 2 i: 1149 loss: 0.060613248497247696\n",
      "epoch: 2 i: 1159 loss: 0.058452457189559937\n",
      "epoch: 2 i: 1169 loss: 0.06048540398478508\n",
      "epoch: 2 i: 1179 loss: 0.05793175846338272\n",
      "epoch: 2 i: 1189 loss: 0.063071109354496\n",
      "epoch: 2 i: 1199 loss: 0.06586619466543198\n"
     ]
    }
   ],
   "source": [
    "pixelCNN.train(True)\n",
    "EPOCH = 3\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "j = 0\n",
    "for epoch in range(EPOCH):\n",
    "  pixelCNN.train()\n",
    "  for i, labels in enumerate(trainloader, 0):\n",
    "    labels = labels.to(device)\n",
    "    # print(\"Labels:\", labels.shape)\n",
    "   \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = pixelCNN(labels.float())\n",
    "    # print(\"Outout:\", outputs.shape)\n",
    "    loss = criterion(outputs, labels.long())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss = loss.item()\n",
    "    # print statistics\n",
    "    j += 1 \n",
    "    if ((i+1) % 10 == 0):\n",
    "      with torch.set_grad_enabled(False):\n",
    "        val_batch = next(iter(testloader))\n",
    "        val_batch = val_batch.to(device)\n",
    "\n",
    "        val_output = pixelCNN(val_batch.float())\n",
    "        val_loss_item = criterion(val_output, val_batch.long()).item()\n",
    "        val_loss.append(val_loss_item)\n",
    "      print(\"epoch:\", epoch, \"i:\" , i, \"loss:\", loss, \"val loss:\", val_loss_item)\n",
    "    train_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "W_bf8bFQzNb5",
    "outputId": "09b51a4f-61db-4696-b58f-3277e4c085b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9b3/8ddnZpJJQhKyE0iAgOyL\nikbAi7stIlppa93X1kqv1ardfqWbWpde23uvvfVelVqvxVqrRamVChYVUW5V1KCyQ9ghLFnJRtaZ\n+fz+mEnMngCTTE78PB8PHpk55zvnfHJI3vnO95zzHVFVjDHGOJ8r0gUYY4wJDwt0Y4wZICzQjTFm\ngLBAN8aYAcIC3RhjBghPpHaclpamOTk5kdq9McY40tq1a0tUNb2jdREL9JycHPLy8iK1e2OMcSQR\n2dvZOhtyMcaYAcIC3RhjBggLdGOMGSAiNoZujBl4GhsbKSgooK6uLtKlOF5MTAzZ2dlERUX1+DUW\n6MaYsCkoKCAhIYGcnBxEJNLlOJaqUlpaSkFBAaNGjerx62zIxRgTNnV1daSmplqYnyARITU19Zjf\n6VigG2PCysI8PI7nODou0PMLq3jk9W2UVNdHuhRjjOlXHBfo2wurefStHZQdbYh0KcYY0684LtCb\n2OdyGGPaKi8v5/HHHz/m182dO5fy8vJjft3NN9/MSy+9dMyv6y2OC/SmYSXFEt0Y01pnge7z+bp8\n3fLly0lKSuqtsvqM4y5btNMtxjjDL/6+ic0HK8O6zUnDErn3S5M7Xb9gwQJ27tzJqaeeSlRUFDEx\nMSQnJ7N161by8/P58pe/zP79+6mrq+Ouu+5i/vz5wGdzS1VXV3PxxRdz1lln8d5775GVlcUrr7xC\nbGxst7WtXLmSH/zgB/h8Ps444wyeeOIJvF4vCxYsYOnSpXg8HmbPns1//Md/8OKLL/KLX/wCt9vN\n4MGDWb16dViOj+MCvYkNuRhj2nr44YfZuHEjn376KW+//TaXXHIJGzdubL6W++mnnyYlJYXa2lrO\nOOMMLr/8clJTU1ttY/v27Tz//PP8/ve/58orr2TJkiVcf/31Xe63rq6Om2++mZUrVzJu3DhuvPFG\nnnjiCW644QZefvlltm7diog0D+vcf//9rFixgqysrOMa6ulMt4EuIk8DlwJFqjqli3ZnAO8DV6tq\nrw0q2RVRxjhDVz3pvjJ9+vRWN+Y8+uijvPzyywDs37+f7du3twv0UaNGceqppwJw+umns2fPnm73\ns23bNkaNGsW4ceMAuOmmm3jssce44447iImJ4ZZbbuHSSy/l0ksvBWDWrFncfPPNXHnllXz1q18N\nx7cK9GwMfREwp6sGIuIGfgW8HoaaesR66MaY7gwaNKj58dtvv82bb77J+++/z7p165g2bVqHN+54\nvd7mx263u9vx9654PB4+/PBDvva1r/Hqq68yZ04wShcuXMiDDz7I/v37Of300yktLT3ufbTaX3cN\nVHW1iOR00+w7wBLgjDDU1I1gF91Oihpj2kpISKCqqqrDdRUVFSQnJxMXF8fWrVtZs2ZN2PY7fvx4\n9uzZw44dOxgzZgzPPvss5557LtXV1dTU1DB37lxmzZrF6NGjAdi5cyczZsxgxowZvPbaa+zfv7/d\nO4XjccJj6CKSBXwFOJ9uAl1E5gPzAUaMGHGc+zuulxljPgdSU1OZNWsWU6ZMITY2liFDhjSvmzNn\nDgsXLmTixImMHz+emTNnhm2/MTEx/OEPf+CKK65oPin6r//6r5SVlTFv3jzq6upQVR555BEAfvjD\nH7J9+3ZUlQsvvJBTTjklLHWI9mDsItRDf7WjMXQReRH4T1VdIyKLQu26HUPPzc3V4/nEohWbDvOt\nZ9fy6nfOYkrW4GN+vTGm92zZsoWJEydGuowBo6PjKSJrVTW3o/bhuMolF3ghNO9AGjBXRHyq+rcw\nbLsd66AbY0zHTjjQVbX5FHKLHnqvhLkxxkTC7bffzrvvvttq2V133cXXv/71CFXUsZ5ctvg8cB6Q\nJiIFwL1AFICqLuzV6jquh+C++3rPxpjPq8ceeyzSJfRIT65yuaanG1PVm0+omh6wIRdjjOmY4+Zy\naWKXLRpjTGuOC3S7bNEYYzrmuEBvYmPoxhjTmuMC3Xroxphwio+P73Tdnj17mDKl0yms+h3HBXoT\n66AbY0xrjps+V5rmcrExF2P6t9cWwOEN4d1m5lS4+OEumyxYsIDhw4dz++23A3Dffffh8XhYtWoV\nR44cobGxkQcffJB58+Yd067r6uq47bbbyMvLw+Px8Mgjj3D++eezadMmvv71r9PQ0EAgEGDJkiUM\nGzaMK6+8koKCAvx+Pz//+c+56qqrjvvb7inHBbpdt2iM6cpVV13F3Xff3RzoixcvZsWKFdx5550k\nJiZSUlLCzJkzueyyy5rva+mJxx57DBFhw4YNbN26ldmzZ5Ofn8/ChQu56667uO6662hoaMDv97N8\n+XKGDRvGsmXLgODEYH3BeYEeYv1zY/q5bnrSvWXatGkUFRVx8OBBiouLSU5OJjMzk+9+97usXr0a\nl8vFgQMHKCwsJDMzs8fb/ec//8l3vvMdACZMmMDIkSPJz8/nzDPP5KGHHqKgoICvfvWrjB07lqlT\np/L973+fH/3oR1x66aWcffbZvfXttuK4MXTroBtjunPFFVfw0ksv8Ze//IWrrrqK5557juLiYtau\nXcunn37KkCFDOpwL/Xhce+21LF26lNjYWObOnctbb73FuHHj+Pjjj5k6dSo/+9nPuP/++8Oyr+44\nt4duXXRjTCeuuuoqbr31VkpKSnjnnXdYvHgxGRkZREVFsWrVKvbu3XvM2zz77LN57rnnuOCCC8jP\nz2ffvn2MHz+eXbt2MXr0aO6880727dvH+vXrmTBhAikpKVx//fUkJSXx1FNP9cJ32Z7jAv2zMS9L\ndGNMxyZPnkxVVRVZWVkMHTqU6667ji996UtMnTqV3NxcJkyYcMzb/Pa3v81tt93G1KlT8Xg8LFq0\nCK/Xy+LFi3n22WeJiooiMzOTn/zkJ3z00Uf88Ic/xOVyERUVxRNPPNEL32V7PZoPvTcc73zoq/OL\nufHpD1ly25mcPjKlFyozxhwvmw89vI51PnTHjaE3sSEXY4xpzYFDLpGuwBgz0GzYsIEbbrih1TKv\n18sHH3wQoYqOj+MCvYl10I3pn1T1mK7v7g+mTp3Kp59+GukyWjme4XDHDbl8dqdohAsxxrQTExND\naWmp3cl9glSV0tJSYmJijul1juuhO+wPvzGfK9nZ2RQUFFBcXBzpUhwvJiaG7OzsY3qN4wK9ifUA\njOl/oqKiGDVqVPcNTa9w4JCLMcaYjnQb6CLytIgUicjGTtZfJyLrRWSDiLwnIqeEv8z2rH9ujDGt\n9aSHvgiY08X63cC5qjoVeAB4Mgx1dS7URbcRF2OMaa3bMXRVXS0iOV2sf6/F0zXAsY3iHyOxQRdj\njOlQuMfQbwFe62yliMwXkTwRyTvRs+Bqgy7GGNNK2AJdRM4nGOg/6qyNqj6pqrmqmpuenn6c+znO\nAo0xZoALy2WLInIy8BRwsaqWhmOb3bIOujHGtHLCPXQRGQH8FbhBVfNPvKRu9hf6anlujDGtddtD\nF5HngfOANBEpAO4FogBUdSFwD5AKPB6av8HX2dSO4eC0OSKMMaav9OQql2u6Wf9N4Jthq6iH7LJF\nY4xpzXl3iloH3RhjOuS4QG9ily0aY0xrjgv05pOilufGGNOK8wLdhlyMMaZDjgv0JtZBN8aY1hwY\n6NZFN8aYjjgw0IPsAy6MMaY1xwW6jaEbY0zHHBfoTax/bowxrTku0Js76JboxhjTivMC3cZcjDGm\nQ44L9CZ2p6gxxrTmuEC3/rkxxnTMcYHexK5aNMaY1hwX6E1D6BboxhjTmvMC3QZdjDGmQ44L9CbW\nQTfGmNYcF+h21aIxxnTMcYHexOZyMcaY1roNdBF5WkSKRGRjJ+tFRB4VkR0isl5ETgt/me1ZnBtj\nTGs96aEvAuZ0sf5iYGzo33zgiRMvq3M25GKMMR3rNtBVdTVQ1kWTecAfNWgNkCQiQ8NVYOd19fYe\njDHGWcIxhp4F7G/xvCC0rB0RmS8ieSKSV1xcfFw7s8sWjTGmY316UlRVn1TVXFXNTU9PP9GthaUm\nY4wZKMIR6AeA4S2eZ4eW9Qq7U9QYYzoWjkBfCtwYutplJlChqofCsN0O2UlRY4zpmKe7BiLyPHAe\nkCYiBcC9QBSAqi4ElgNzgR1ADfD13iq2JeugG2NMa90Guqpe0816BW4PW0XdsJOixhjTMQffKRrp\nCowxpn9xXKA3nxS1QRdjjGnFcYHusqtcjDGmQ44L9KYPiQ5YohtjTCuOC3RXKNAtz40xpjUHBnrw\nq/XQjTGmNQcGetOQS4QLMcaYfsZxgS7WQzfGmA45LtA/G0O3QDfGmJYcG+g25GKMMa05MNCDX23I\nxRhjWnNcoIv10I0xpkOOC/TP7hS1RDfGmJYcGOihHrp10Y0xphXnBrrluTHGtOK4QJdQxXZS1Bhj\nWnNcoNtcLsYY0zEHBnrwq/XQjTGmNQcGuo2hG2NMR3oU6CIyR0S2icgOEVnQwfoRIrJKRD4RkfUi\nMjf8pTbtK/jVeujGGNNat4EuIm7gMeBiYBJwjYhMatPsZ8BiVZ0GXA08Hu5Cm9hli8YY07Ge9NCn\nAztUdZeqNgAvAPPatFEgMfR4MHAwfCW25rYhF2OM6ZCnB22ygP0tnhcAM9q0uQ94XUS+AwwCvhCW\n6jpgQy7GGNOxcJ0UvQZYpKrZwFzgWRFpt20RmS8ieSKSV1xcfFw7EhFE7NZ/Y4xpqyeBfgAY3uJ5\ndmhZS7cAiwFU9X0gBkhruyFVfVJVc1U1Nz09/fgqJjiObkMuxhjTWk8C/SNgrIiMEpFogic9l7Zp\nsw+4EEBEJhIM9OPrgveAS2zIxRhj2uo20FXVB9wBrAC2ELyaZZOI3C8il4WafR+4VUTWAc8DN2sv\njomI9dCNMaadnpwURVWXA8vbLLunxePNwKzwltY5l42hG2NMO467UxSaxtAt0I0xpiUHB3qkqzDG\nmP7FkYEudlLUGGPacWSgu0Rs+lxjjGnDoYFuPXRjjGnLoYEu+G0Q3RhjWnFkoLtdFujGGNOWIwM9\nyu2i0W+BbowxLTky0D1uwRcIRLoMY4zpV5wZ6C6h0W+BbowxLTk00F02hm6MMW04MtCD86FHugpj\njOlfHBroduu/Mca05chAdwkEP8bUGGNME0cGenAul0hXYYwx/YsjAz04l4slujHGtOTIQBesh26M\nMW05M9DtAy6MMaYdRwZ68KSoMcaYlhwZ6NZDN8aY9noU6CIyR0S2icgOEVnQSZsrRWSziGwSkT+H\nt8zWahr87C+r7c1dGGOM43i6ayAibuAx4ItAAfCRiCxV1c0t2owFfgzMUtUjIpLRWwUDbDlU2Zub\nN8YYR+pJD306sENVd6lqA/ACMK9Nm1uBx1T1CICqFoW3TGOMMd3pSaBnAftbPC8ILWtpHDBORN4V\nkTUiMqejDYnIfBHJE5G84uLi46vYGGNMh8J1UtQDjAXOA64Bfi8iSW0bqeqTqpqrqrnp6enHt6fS\nnXwn7g0SqT6Bco0xZuDpSaAfAIa3eJ4dWtZSAbBUVRtVdTeQTzDgw69wI98P/IEs95Fe2bwxxjhV\nTwL9I2CsiIwSkWjgamBpmzZ/I9g7R0TSCA7B7ApjnZ/xJgAQF6jplc0bY4xTdRvoquoD7gBWAFuA\nxaq6SUTuF5HLQs1WAKUishlYBfxQVUt7pWJvIgAJUkvA7v83xphm3V62CKCqy4HlbZbd0+KxAt8L\n/etdoR56PLX4Akq03TZqjDGAE+8UbQp0qbW7RY0xpgXnBjq17C+zcXRjjGnivECPGkQAIUFq+fkr\nGyNdjTHG9BvOC3SXi1qJJR6by8UYY1pyXqADNcQRTy2DY6MiXYoxxvQbjgz0+MHJJEgNpwxvdzOq\nMcZ8bjky0L2DBhNPLYJdsmiMMU0cGejiTSRBamnwBSJdijHG9BvODPSYBOKllga/P9KlGGNMv+HI\nQMebQAK1NPrtxiJjjGni0EBPDPbQbcjFGGOaOTTQE4inlobGxkhXYowx/YYzAz0uDYCGSvvUI2OM\naeLMQI8PfgZ1Q2VhhAsxxpj+w6GBPgSA2PqSCBdijDH9hzMDPSEY6IMaLNCNMaaJMwN9UHDIJaq2\nhLpGuxbdGGPAqYHujafeFUeGlHPn859EuhpjjOkXnBnowNGoFNKlnNc324lRY4yBHga6iMwRkW0i\nskNEFnTR7nIRURHJDV+JHauJTiWdit7ejTHGOEa3gS4ibuAx4GJgEnCNiEzqoF0CcBfwQbiL7Igv\nLoN0Ke+LXRljjCP0pIc+HdihqrtUtQF4AZjXQbsHgF8BdWGsr1MpQ7It0I0xpoWeBHoWsL/F84LQ\nsmYichowXFWXdbUhEZkvInkikldcfGJ3eSamZTFYavDScELbMcaYgeKET4qKiAt4BPh+d21V9UlV\nzVXV3PT09BPbcXwmAGk2jm6MMUDPAv0AMLzF8+zQsiYJwBTgbRHZA8wElvb6idHQ3aLpYoFujDHQ\ns0D/CBgrIqNEJBq4GljatFJVK1Q1TVVzVDUHWANcpqp5vVJxk9B8LjaObowxQd0Guqr6gDuAFcAW\nYLGqbhKR+0Xkst4usFOhHnqGBboxxgDg6UkjVV0OLG+z7J5O2p534mX1wKA0AiqkSzlbDlUycWhi\nn+zWGGP6K8feKYo7ijISSKeC8hr7oAtjjHFuoAPFOpgMOYJIpCsxxpjIc3Sg79Mh5EghjX77bFFj\njHF0oB/yZDNSDnPz/74f6VKMMSbiHB3o03NnEC1+hktRpEsxxpiIc3SgT5hyGgCj5RArt9g0usaY\nzzdHB7orfRwQDPRbnsnjyNEG+wQjY8znlqMDnbgUyt0pTHbtAWDaA29w5e9sPN0Y8/nk7EAHdsVO\nIVfym5+vL7C5XYwxn0+OD/QRp17IcFcxmZRGuhRjjIkoxwd62qTzALjC/U5kCzHGmAhzfKCTeTL/\n8J/B96NeYoZsiXQ1xhgTMc4PdJeL54ffwxGN5wbP6wDkLFjG2r1HIlyYMcb0LecHOiBRMbzkP4eL\nXHmkE5xO9/In3uMP7+6mpLo+wtUZY0zfGBCB7vW4eN5/AVHi5wr3283Lf/H3zVz/1Af88f097C+r\n4cd/3YDP5n0xxgxQPZoPvb974MtTmL6pkHf9k/l/UYs5z72Ouxtu5yBpbD1cxT2vbAI2AXD5aVnk\n5qREtmBjjOkFA6KHnpEQw56HL2Hw5b9hoe9LTJB9/Cb6cUDbtd18qJLDFXXU++yOUmPMwCKq7UOv\nL+Tm5mpeXvg/djRnwTJucL/OA1GLeM1/BuOkgPmN32OaawcHNI33A5Ob2776nbOYkjU47DUYY0xv\nEZG1qprb4bqBFugl1fX8y4Ov8fuo/2SWayMe+WzMvEa9fK3hXvI1G19otGnHQxfjcbvw+QO4XcKT\nq3eRkejlK9Oyw16bMcacqK4CvUdj6CIyB/gt4AaeUtWH26z/HvBNwAcUA99Q1b0nVPVxSov38m9X\n5HLTiwsAuNC1lpvcr1NHNLPda1nu/QkfBcZxRBN40X8uY34Ki791Zrs5YL4yLZsVmw4zbHAsU7Ot\nF2+M6f+67aGLiBvIB74IFAAfAdeo6uYWbc4HPlDVGhG5DThPVa/qaru91UMHUFXO+fdV7C+rbV7m\nxs9foh/Aj4sZrq2UaTxJHOVx/2UUajIr/GdQzGA0dFrhje+ewxd/s7r59T+dO5FbzxndK/UaY0xP\nndCQi4icCdynqheFnv8YQFX/rZP204D/UdVZXW23NwMdIBBQAqqM+elr7dYNoYxy4nku+pfkuoIT\ne9WrBzcB1ulJLPJdxPLADPy4W71uwcUTSIjxUFPv54l3dvKlk4fyi3lTqKhpZPov3+RHcybwjbNG\n9dr3ZIwxJxroXwPmqOo3Q89vAGao6h2dtP8f4LCqPtjBuvnAfIARI0acvndv74/KqCortxRRdrSB\nU4Yn8Y1FH/Hy7f/C9IdWIgRIpIYMKed69xvUE82Fro85yXWInYGhPOOfzceBsaRJBWWayG4dSg1e\nRskhduowFBc/vGg8b7/+Cjt1GGUkMiYjnrEZ8Txx/ekAfPXxdzljVAo/vngiPn+AP63Zy7UzRhLt\nGRAXGBlj+lifBbqIXA/cAZyrql3eotnbPfTuPPzaVha+s7PVsp9dMpGHlm1itmstd3teYqJrf7vX\nVWosiVLLx4ExvOQ/lzJN4PGo3/KpnsTlDfc1D9k89JUpXDdjJDkLlgGw5+FLeO6Dvfz05Y2MyYhn\nwZwJfGHSkB7XW1XXSMGRWiYOTTyB79oY43R9MuQiIl8A/ptgmHf7IZ+RDnSAep+f59bs41f/2MrS\nO85ifGYCR+t9TL53BQAj5TAnyy4OaBqjXYfI4AgTXfs4rClc7P6QbClptb3Dmsy/N17Fu4HJHCa1\n1borc7NZnFfQatnan32B1Hgv976ykWfe38srt8/ilOFJHdb6lcff5ZN95ex5+JIwHgFjjNOcaKB7\nCJ4UvRA4QPCk6LWquqlFm2nASwR78tt7UlR/CPTOBALKb1du59oZI5jxy5UAnDYiiY/3lbdopYyU\nQr7q/j+2BkYQTSO3eF7jZNduAN71T2aPZrJds1jsPw8Pfu72LCFFKtmjmbzvn8wHOrHVfs8em8az\nt8xotay4qp4/rdnLb1cGD+uuX87F5ZLe++aNMf3aCV+HLiJzgf8ieNni06r6kIjcD+Sp6lIReROY\nChwKvWSfql7W1Tb7c6B35oFXN+P1uHj87Z0kxUVRXtMIwDdmjeLpd3cThY/TXfmcIVv5ivufJEs1\nyVJNqSYQQwMxNFBMEhmU4xLlB43f4iX/ue32kxwXxbO3zCA22s0vl21h5dbP3vDcP28yF03OZEhi\nTJ9938aY/uNzdWNRpAQCysGKWuK9Hs7+9Sqq6nwA5MpWrve8SaUO4nn/BWzRkcRQz6LoXzPTtYVS\nTaBIk1gZOI0KHcRWHcGHgQlE46OKuE73lxDj4dGrp3H+hIzm/a8/UMGpnQzZGGMGBgv0PubzB/jd\n6l38+4pt3PulScRFu3nmvb288K2ZFFXW8YVHVpNCJde6VzJUyhgphznL3TyCRaXG0oiHP/jm4MfN\n3wMzyZYSSjSRHdr6Dtac1Di++8VxFFfV8+CyLfz51hn8y0lpff0tG2P6iAV6BKgqtY1+4qI7vxn3\n/r9v5uTswfx93UHOTDrC79YUcZ1nJWe7NjCYo4xxHWzVPqDCysA0Xg/k8op/Fg1EtdtmTJSL88Zl\nsPCG0ymtrkcJ3j1rjBkYLNAdorymgRfzCshI9HL3Cx8TjY/Rcohvepaxwn8Gp7vyudj1ISNcxRRq\nEot8c9im2fhxU6LByxk3aQ7Q+qTpuntmc6C8lmFJMSTFRff9N2aMCRsLdAd6e1sR/3JSWvsbkFQp\nWvcPti55iHPcG9q9bmMgh2f8synVRFYFTkURWgZ8tMdFeryX+eeM5qyxaVTV+TglezDFVfVk2IlW\nY/o9C/QBKBBQ1rz/Ds8sW8UX3R9zROPZqcO4w/O35uvjKzSOvMB4nvLPZYZrCxsCo8iUI7zln8ah\nNtfJQ/DSzL9+u8sZG4wxEWaBPoDV+/zUNvipqvMxPCWO7QWHqdy7np3/eIwsipnu2kqUtP4wjxr1\nEkC4t/FmlgTOabfNW88exY1n5hAX7SYpLhp3J9e9FxypISEK1u3cR0NU8jHd+WqMOT4W6J9j76z5\nkFf//iJ7A0MY6Srk08AY/tWzlDmuj4ilgUKSKdVE1gdG82bgNN4NTKGe1uPs/33NNB5+bSvL7zwb\nb5SLyrpG3t9Zyl0vfMoCz5+5yv02Z9f/F//40SVkJ3d+qaUx5sRZoH/OBQJK6dEG9pXVcPrIZPL2\nlPGNhW/wDc8/GEYp6VLOTNcWYqWB/YF0GvDwbmAKbwZOA2CO60N+77+U3Tq01XZTqeAf3gWkSwX3\nNN7EH/0X8f6PL+BgeR2nj0yOxLdqzIBngW7a2V1ylKykWKI9Loqq6igpKeW/f/87vpfwBgdqopjp\n2kyMNDa3r9Q4XvNPp54oRkohtXiZ4/4IgGqNoYJBXF5/H6e5trNeT2L8+MmMy0zglOwkymsaSIqL\n4q8fH+DJG1v/HBZV1TEo2sP2ompSB0Wzo7ia88dn9OmxMMZJLNDNMdl4oIIde/Yx3L+XV9fu5mBx\nCT/x/Jk4qcdLIwc0jfGyn9WBkzmsySzxn8Ofox9qHqv3qYv/8X+ZJf6zqdI4BstR/LgYLsUUaRJT\nZDe7dSj7NIMALuqIJoYGYqmnnHjqiWb3v82lqt7Hyfe9DsCdF4zh9gvG4PW4afQHWL7hEM+8t6fL\nk7j+gHK0wUdiTPvr9Y1xKgt0c0LKaxp4Y3Mh/oBScKSWa2eMIMZXhT86kT+u2cv/bS/hD+fWkLd6\nOc8VpPE19ztc6v6gR9sOqFBKIrHUE00j+3QIz/sv4CgxnONazzAp4bCmssw/g2WBmcTQgB9Xu3H+\nljITY5gzJZNF7+0B4IF5k/n5K5uIjXLzrXNHc+nJw1ict5/vhe6wPfvXq7h2xggmZCZQ1+jnm2eN\nxuUS9pfVMHRwDB5353PX5+0pY1xmAqvzixmZMqh/fFyhrwH/4pu4fuM0Lv7Sldx4Zk6kKzJhZIFu\n+lTZ0Qb25a+jdP0K3ss/yMljR/PR9gIKNI0UqtihWUx3bUWBbClhrBTgw0MjHia69jZfdnlIU9ge\nyGK06xDZUkKVxpIgtdRqNLt1KG78ePDTgIddOhQ3igcfilBDDCOlkM2BkQDs0qHs1kyypIQ46nkt\nMJ2DmsYs10ZyXdvIDwyniljWBU5ipBSyU4dSSTyZlBItPvbpEEABIZpGBKW++U7d1lcBPfjlKcR7\nPVTX+/jZ3zYyPSeF2ZOHkDIomtpGP9sLqxmZGsepw5PYV1bDFyYOoexoA4vz9nPLWaP4YHcZL3y4\nj8GxUaTFe/n+7PFsPVzJhMxEPG6httHPvtIaJg8L3kwmEtx/gy/AO/nFPPenp1gU/WsARtf9iT/d\neuYJTQdRdrSBmChXl3c9N2ZO4TMAAAxUSURBVCmqrCN5UDRRXfwR/Nw6+AlF+R/yol7It84Z3WVH\noSsW6Kbfqmv0s/VwFfmFVVx+WjYNvgD/8bf3eOuTbezWTNbfdxGVNfV8vOJPuHesYGNdBkOkjGFS\nig83flzEU8twKcaHGx9uYmhghBRyWFNIk0oacTNYatrtO6CCS7TDZfXq4aCmMkxKicLPYZLJoJwC\nTSdVKgm+SqjByxFNIEOOUKKD2a5ZCEoCtezUYUx17caPiy2BEZToYGrxMkH2sUOz8OGmQNMZIweY\n7c7jn4EpHNJUyjWeRtwoQhVxxNCAoAyRI+zWoYyQQhKp4YCmkRcYTwWDcOMnGh8nyUEejf6f5j+K\nb/hPJy8wjp06jHzN5oCm4ceNBx9C8E9UND7u/uI4DlQ08NyHBQyTUryDkimqbqCaWDIpo5Bk/n7X\n+WTEKt/61VMMkzIqGMQ7gZOZMSqVhBgPsydl8v+WrAfg3HHpfGFiBm9vKyYrOZaD5bVcNDmT19du\n4e3dtTTi4eTswawvqODb553EeeMzKKmuZ0iiF6/Hzb+9toV3d5Ry54VjeXTldn40ZwLTRgTPx3y0\n5wi3nDWKgCqvrj9ETuogfIEA03NSWLO7jDuf/wSAW84axf/+czfnjEvngXmTSYv3Ehft5lBFHX9a\ns5c7LxxLfWMAlwsKK+uJi3aTnuAloIogeFzCtsIqkuKiGDo4lvzCKvaW1rDtcCXXzxzJkZpGyo42\nEO/1kDwoin2lNYzPTCDe62n+I9voD7Cn5Cj/9eZ2Hsq/lCQ5ylX1P2foKRfyX1dPO67fGQt0M2Ad\nrfdRUdtIRoK3ucdzqKKWRK+bKLebaJdS41NifZX89Y23+c0HVaTFupg9aDvZFDF8yiwK02by2yUr\nuXV6GofzlnJQU7lgaD3Vhbup1DiKNYnhrmJKNYEsKaVcB5EY+gPhx0UCNRRqCsOliGFSCkAA4SQ5\nyCc6Fg8+cqSQJDkarFm9DJLWH+i1K5DJaNfhsB2Xv/rPYnsgm7s8S1qd3A6oUEkcidQQCL2z8Eig\n3et96sIjAWo1mlhpoFHdHNRUMuUI3hbbWxcYTR3R1KiXMhKJow5FqCOaBGoZRC2DpI54amnAwzgp\noIwE3ATYqcM4ogkcJYYsKSEvMJ49OoQEajnFtZMUKokSPw0afAeWJEcp1URKNZGRUsghUvCrm1Sp\noJpYUqlklw5lgms/RzSBaBqDteGlQNNpVA8uAiTJUaa6drEjkMUhTaGIZJKpogYvAVx4aaSOKE51\n7SSGRmrUy2YdiQ83UfiIDnUlKognQ47gQinSJIZLEfHUkRcYxxESqCeKZKpIliqGSzEPRC0CYFNg\nJJc0/JI9D196XP+3FujGhEFFbSMoDI7r/CSrP6BsOVRJVlIs8VGK2xNNYVUdu4qP4gnUMzq6goSh\nYzhUXIJL/QyqPYg3NoGYoeMprqjmvY07yPTUcFJaLMUV1fxuxVqSk5O5+wvjeXBVITfkVBHImMSa\nQhfr/rmMoVJKEtXgjua00UMYMWwo8VkT+fMuLyePyeGCCRnsO3iYxf9YSdGudWRLCclUUUYC8VHB\n4ZtKjcNNABeKoJQTT7YUU6fRDJNSNmoOQ+QIOVLIYU3m/cAkpp92OkWfLGe2O/g7HEcdyVLNUY3B\nTYBoGqkmjmpiOKoxHCWWeGrZo0PIkHJq8ZItxaRRgVcaKdFETpbdze+YDmhq8N2EukmSKkbLYQo1\niRSpIl7qKNN4BnMUASqJI4EaavESL3UUaRIJ1ODDTTQ+ovC1eydWrINJl4ou/7/9KvhxEd3mxrzj\nVaWxLGi8lT06hEe/dzMnpccf13Ys0I0xxyQQUBRwyWdj9J2prGskocUwA8DB8trmO41VtdNt1DT4\nyC+sZt3+cr48KZHt+wrIHTUEEoZQ1+jHH1AGeT0UVtSSPMiLaoBofw1+zyB2Hi7lpOQofvtuEd86\nZzRxbsVVvhvSxoEGgmc8XG4aGhrYsHkDew6Vct6EDIhOIHnoaH71ykdclOOipuwAQ1LTSI1RthUd\nZdLwDMorK8geOQaNz+Tfl60nN6aA1IRY0gbHU9Uo/ORvm3j++nFsqIxDfPWMSfQTN+Qk7luWT1xh\nHkNiAqR4A5TLYG75Yi6u+FQKGhN5a1c1V58x4oQ+JN4C3RhjBoiuAt1ORRtjzABhgW6MMQNEjwJd\nROaIyDYR2SEiCzpY7xWRv4TWfyAiOeEu1BhjTNe6DXQRcQOPARcDk4BrRGRSm2a3AEdUdQzwG+BX\n4S7UGGNM13rSQ58O7FDVXaraALwAzGvTZh7wTOjxS8CF0t2pcWOMMWHVk0DPAva3eF4QWtZhG1X1\nARXQwUfiGGOM6TV9elJUROaLSJ6I5BUXF/flro0xZsDrSaAfAIa3eJ4dWtZhGxHxAIOB0rYbUtUn\nVTVXVXPT09OPr2JjjDEd6n76NPgIGCsiowgG99XAtW3aLAVuAt4Hvga8pd3csbR27doSEdl77CUD\nkAaUHOdr+5pTarU6w88ptVqd4dXbdY7sbEW3ga6qPhG5A1gBuIGnVXWTiNwP5KnqUuB/gWdFZAdQ\nRjD0u9vucXfRRSSvszul+hun1Gp1hp9TarU6wyuSdfakh46qLgeWt1l2T4vHdcAV4S3NGGPMsbA7\nRY0xZoBwaqA/GekCjoFTarU6w88ptVqd4RWxOiM226IxxpjwcmoP3RhjTBsW6MYYM0A4LtC7m/kx\nAvXsEZENIvKpiOSFlqWIyBsisj30NTm0XETk0VDt60XktF6u7WkRKRKRjS2WHXNtInJTqP12Ebmp\nj+q8T0QOhI7rpyIyt8W6H4fq3CYiF7VY3qs/GyIyXERWichmEdkkIneFlverY9pFnf3qmIpIjIh8\nKCLrQnX+IrR8VGjW1h0SnMU1OrS801ldO6u/D2pdJCK7WxzTU0PLI/P7pKqO+UfwOvidwGggGlgH\nTIpwTXuAtDbLfg0sCD1eAPwq9Hgu8BogwEzgg16u7RzgNGDj8dYGpAC7Ql+TQ4+T+6DO+4AfdNB2\nUuj/3QuMCv08uPviZwMYCpwWepwA5Ifq6VfHtIs6+9UxDR2X+NDjKOCD0HFaDFwdWr4QuC30+NvA\nwtDjq4G/dFV/mP/vO6t1EfC1DtpH5P/eaT30nsz82B+0nH3yGeDLLZb/UYPWAEkiMrS3ilDV1QRv\n9DqR2i4C3lDVMlU9ArwBzOmDOjszD3hBVetVdTewg+DPRa//bKjqIVX9OPS4CthCcGK6fnVMu6iz\nMxE5pqHjUh16GhX6p8AFBGdthfbHs6NZXTurP2y6qLUzEfm/d1qg92Tmx76mwOsislZE5oeWDVHV\nQ6HHh4Ehocf9of5jrS2SNd8Rerv6dNMwRhf19Gmdobf70wj21PrtMW1TJ/SzYyoibhH5FCgiGG47\ngXINztradp+dzeraJ8ezba2q2nRMHwod09+IiLdtrW1q6tVanRbo/dFZqnoawQ8AuV1Ezmm5UoPv\ns/rltaH9uTbgCeAk4FTgEPCfkS3nMyISDywB7lbVypbr+tMx7aDOfndMVdWvqqcSnPRvOjAhwiV1\nqm2tIjIF+DHBms8gOIzyowiW6LhA78nMj31KVQ+EvhYBLxP8oSxsGkoJfS0KNe8P9R9rbRGpWVUL\nQ79AAeD3fPYWOqJ1ikgUwZB8TlX/Glrc745pR3X212Maqq0cWAWcSXB4omlakpb77GxW1z79GW1R\n65zQ8Jaqaj3wByJ8TJ0W6M0zP4bOfF9NcKbHiBCRQSKS0PQYmA1s5LPZJwl9fSX0eClwY+gM+Eyg\nosVb9b5yrLWtAGaLSHLoLfrs0LJe1ebcwlcIHtemOq8OXfEwChgLfEgf/GyExmv/F9iiqo+0WNWv\njmlndfa3Yyoi6SKSFHocC3yR4Hj/KoKztkL749l0nFvO6tpZ/WHTSa1bW/whF4Jj/S2Pad//PoXr\n7Gpf/SN49jif4FjbTyNcy2iCZ9fXAZua6iE4rrcS2A68CaToZ2fKHwvVvgHI7eX6nif41rqR4Fjd\nLcdTG/ANgieadgBf76M6nw3VsZ7gL8fQFu1/GqpzG3BxX/1sAGcRHE5ZD3wa+je3vx3TLursV8cU\nOBn4JFTPRuCeFr9XH4aOzYuAN7Q8JvR8R2j96O7q74Na3wod043An/jsSpiI/N/brf/GGDNAOG3I\nxRhjTCcs0I0xZoCwQDfGmAHCAt0YYwYIC3RjjBkgLNCNMWaAsEA3xpgB4v8DPHMn6jT80HYAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train loss: \")\n",
    "plt.plot(train_loss, label = \"train_loss\")\n",
    "plt.plot(np.arange(0, len(train_loss),int(len(train_loss)/len(val_loss))),val_loss, label = \"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UNoj9L6spMZ"
   },
   "outputs": [],
   "source": [
    "torch.save(pixelCNN.state_dict(), 'drive/My Drive/Colab Notebooks/pixel_cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-uk12A9aFzP"
   },
   "outputs": [],
   "source": [
    "pixelCNN = PixelCNN(*args, **kwargs)\n",
    "pixelCNN.load_state_dict(torch.load('drive/My Drive/Colab Notebooks/pixel_cnn_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "-uFdbF_UjXMb",
    "outputId": "13858fcc-a39b-45c1-821d-a776daa4c8ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "image = np.random.choice(4, size=(batch_size, 3, 28, 28)).astype(np.uint8)\n",
    "\n",
    "for k in range(3):   \n",
    "  for i in range(28):\n",
    "    for j in range(28):\n",
    "      in_tensor = torch.from_numpy(image).float()\n",
    "      in_tensor = in_tensor.to(device)\n",
    "      out = pixelCNN(in_tensor)\n",
    "      probs = torch.nn.functional.softmax(out)\n",
    "      # print(probs.shape)\n",
    "      probs = torch.argmax(probs, 1)\n",
    "      probs = probs.to(\"cpu:0\").detach().numpy()\n",
    "\n",
    "      image[:, k, i, j] = probs[:, k, i, j]\n",
    "      \n",
    "      # for b in range(batch_size):\n",
    "      #   image[b, k, i, j] = np.random.choice(4, p=probs[b, k, i, j])\n",
    "\n",
    "\n",
    "image = image * 256 / 3\n",
    "image = image.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDNM9st-jW8O"
   },
   "outputs": [],
   "source": [
    "#Saving\n",
    "torchvision.utils.save_image(torch.from_numpy(image), 'drive/My Drive/Colab Notebooks/sample.png', nrow=10, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "faSDMzxDjW3o"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 5, figsize=(20, 50))\n",
    "count = 0\n",
    "\n",
    "for i in range(5):\n",
    "  for j in range(10):\n",
    "    temp_image = image[count,:,:,:].astype(int)\n",
    "    count += 1\n",
    "    axs[j][i].imshow(temp_image.reshape(28,28,3))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ke7oyHQELOz7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEKIyRE1jWwT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TCojeuHsjWKM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "exercise02.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
